{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd8a369",
   "metadata": {},
   "source": [
    "# The Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00dc8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01add43",
   "metadata": {},
   "source": [
    "# Incrementally building a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dcde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bd9fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.14532223,  0.03427765, -0.23932818, -0.26806998,  0.13617086,\n",
       "         -0.07623744,  0.14864758, -0.14353326, -0.1100736 ,  0.25780845,\n",
       "          0.23938024, -0.11250848,  0.14247474,  0.08472806,  0.28328556,\n",
       "          0.2971233 , -0.18221584,  0.19866034, -0.16255356, -0.07707898,\n",
       "         -0.25140756,  0.18425146,  0.16568023, -0.25954482, -0.20718166,\n",
       "          0.26786005,  0.08648571, -0.22501674, -0.00047126, -0.16660295,\n",
       "          0.06295469, -0.2584609 , -0.0773125 , -0.2489847 ,  0.18208092,\n",
       "         -0.05328953, -0.12804523,  0.12231609, -0.25921783,  0.18115541,\n",
       "         -0.22018923,  0.21779925,  0.25679058,  0.25400782,  0.0788464 ,\n",
       "         -0.06039524,  0.29372126,  0.10503206,  0.09315476, -0.18508509,\n",
       "          0.2914778 ,  0.14632958,  0.22131407,  0.19679469, -0.00283557,\n",
       "          0.05909109,  0.09121853,  0.01628456, -0.05856946,  0.04224259,\n",
       "          0.23779815, -0.09614044,  0.27193218, -0.1669547 ],\n",
       "        [-0.23905799, -0.23610242, -0.21460423,  0.22850215, -0.20972149,\n",
       "         -0.2016481 , -0.16416843,  0.22326487, -0.22006537,  0.16960117,\n",
       "         -0.1769962 , -0.18823072,  0.09098873,  0.15682265, -0.08617207,\n",
       "         -0.27322692, -0.2968842 ,  0.29752815,  0.22778481, -0.08659559,\n",
       "          0.02751142,  0.02823997,  0.05637911, -0.18571216, -0.24159224,\n",
       "         -0.12711094, -0.04769897, -0.09997037,  0.21006215, -0.01766369,\n",
       "         -0.14488065,  0.02066556, -0.25698608, -0.12020208, -0.11415118,\n",
       "          0.29152644,  0.00560093,  0.20426428,  0.10133517, -0.18614423,\n",
       "          0.23545289, -0.1404233 , -0.26831692,  0.14939225,  0.17192084,\n",
       "         -0.1286753 ,  0.08924544, -0.1250465 , -0.2950929 , -0.11168697,\n",
       "         -0.17770234, -0.21099633,  0.07788348, -0.23773028, -0.17341036,\n",
       "          0.06447169, -0.01896772,  0.01262078, -0.12729466,  0.14747265,\n",
       "         -0.27384427, -0.01751438,  0.19522133, -0.273325  ],\n",
       "        [-0.01445279,  0.04843742, -0.00995609, -0.16009414,  0.2446273 ,\n",
       "          0.14537337, -0.10327776,  0.1784741 ,  0.20480072,  0.12293696,\n",
       "          0.18743354,  0.21012819, -0.1833011 ,  0.10094434,  0.20717669,\n",
       "          0.21859598,  0.29171383,  0.20219547,  0.2595079 ,  0.27397734,\n",
       "          0.08541849, -0.25004676,  0.09046048, -0.0922966 ,  0.0702554 ,\n",
       "         -0.18126479, -0.14731218, -0.14776388,  0.0392189 ,  0.07678723,\n",
       "          0.08440715,  0.02557826,  0.02599236, -0.15874168, -0.20850722,\n",
       "         -0.09861985,  0.08565995, -0.16922675, -0.1394838 ,  0.05174029,\n",
       "         -0.14390406, -0.19310081,  0.24771285,  0.02936155, -0.14828615,\n",
       "          0.1752977 ,  0.0524545 , -0.2818827 , -0.0177097 , -0.16761944,\n",
       "         -0.26403478,  0.17074168, -0.06524144,  0.14519382,  0.29659277,\n",
       "         -0.0860465 ,  0.08656019,  0.163923  ,  0.02036619,  0.10769317,\n",
       "         -0.04862449, -0.18984538, -0.29503018, -0.01882759]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 3.71803939e-02,  1.06796980e-01,  1.69355392e-01,\n",
       "          7.80278146e-02, -1.08113542e-01,  2.01786548e-01,\n",
       "         -1.19059905e-01,  2.34338045e-02, -2.17351809e-01,\n",
       "         -2.28868842e-01],\n",
       "        [-8.15006942e-02,  6.45903945e-02,  7.33009875e-02,\n",
       "          2.78874248e-01, -2.63799131e-01,  1.23761237e-01,\n",
       "          1.42243564e-01, -1.43570587e-01, -1.57627076e-01,\n",
       "         -1.72109038e-01],\n",
       "        [ 5.64323664e-02,  2.04361707e-01,  1.20398015e-01,\n",
       "         -1.24625653e-01, -4.22098190e-02,  2.22792596e-01,\n",
       "         -1.01817310e-01,  2.54358441e-01,  1.71979725e-01,\n",
       "          1.33554846e-01],\n",
       "        [-1.45653889e-01, -2.52126694e-01, -5.95994741e-02,\n",
       "          2.65011817e-01,  4.52803075e-02,  2.35649556e-01,\n",
       "          8.24874043e-02,  6.10563755e-02, -6.00045025e-02,\n",
       "          2.06964999e-01],\n",
       "        [ 1.15624309e-01,  1.52994186e-01, -2.28318483e-01,\n",
       "         -2.24624574e-02,  2.68265158e-01,  4.59408164e-02,\n",
       "          1.61584735e-01, -1.74528956e-01, -2.73084402e-01,\n",
       "         -9.20152813e-02],\n",
       "        [-1.70104548e-01,  1.26067072e-01, -2.36836642e-01,\n",
       "         -2.51650870e-01,  3.15270126e-02,  2.54102737e-01,\n",
       "         -1.56456128e-01,  2.37977237e-01, -2.84398437e-01,\n",
       "         -2.32526958e-02],\n",
       "        [ 1.70451313e-01, -7.92291760e-03, -2.50691861e-01,\n",
       "         -2.53104776e-01,  7.14321434e-02,  1.86404586e-01,\n",
       "         -2.17763901e-01, -1.53749600e-01, -2.17037559e-01,\n",
       "          1.00322723e-01],\n",
       "        [-2.14078397e-01,  1.83981955e-02,  7.79769719e-02,\n",
       "         -2.56985128e-02, -4.59197611e-02, -2.83263206e-01,\n",
       "          5.30140400e-02,  1.30424529e-01, -2.70715207e-01,\n",
       "          2.18400359e-03],\n",
       "        [-2.06760377e-01,  7.45612085e-02, -1.74423248e-01,\n",
       "          1.71155870e-01, -2.34001875e-01, -2.53772110e-01,\n",
       "         -2.29459554e-01, -1.82103738e-01, -9.77322161e-02,\n",
       "         -3.40161026e-02],\n",
       "        [-1.59403056e-01, -5.43530136e-02,  1.20333225e-01,\n",
       "         -2.47008801e-01,  4.82852161e-02,  2.04583973e-01,\n",
       "         -2.51628667e-01, -9.86432284e-02,  8.60762000e-02,\n",
       "         -3.57399285e-02],\n",
       "        [ 2.50875384e-01, -2.51996070e-01,  1.51922166e-01,\n",
       "          1.40184879e-01,  1.56729311e-01,  2.39017040e-01,\n",
       "          8.56093466e-02, -2.26930678e-02, -1.32479608e-01,\n",
       "          1.89016879e-01],\n",
       "        [-9.77816433e-02,  2.02375680e-01,  9.08465087e-02,\n",
       "         -2.62346715e-01,  3.75968218e-03,  2.14593410e-02,\n",
       "         -3.93861830e-02, -2.32043862e-03,  2.33054429e-01,\n",
       "          2.13023007e-01],\n",
       "        [-2.26384044e-01, -8.82862657e-02,  1.02946848e-01,\n",
       "         -2.29916647e-01,  2.01019049e-01, -2.46006846e-02,\n",
       "          1.16524726e-01,  6.07791841e-02, -1.44646615e-01,\n",
       "         -1.84530646e-01],\n",
       "        [-2.60509372e-01,  1.49431378e-01, -2.36392930e-01,\n",
       "          2.53304243e-02,  1.59199327e-01,  2.59209305e-01,\n",
       "         -6.17237240e-02, -1.54461071e-01, -1.59205779e-01,\n",
       "         -1.31678581e-03],\n",
       "        [ 2.70171851e-01,  1.44306839e-01, -1.31891623e-01,\n",
       "         -9.97146964e-03,  1.35706991e-01,  9.07139778e-02,\n",
       "          1.29287243e-02,  5.43857217e-02,  5.38893342e-02,\n",
       "         -3.78651321e-02],\n",
       "        [-7.20693320e-02,  1.18209928e-01, -4.97226268e-02,\n",
       "         -6.80825561e-02, -1.55778527e-01, -1.05855465e-02,\n",
       "         -2.24692106e-01,  1.24470115e-01,  7.88861513e-02,\n",
       "          1.76446080e-01],\n",
       "        [ 2.43329853e-01, -6.78176433e-02,  2.08919913e-01,\n",
       "          1.84740484e-01, -1.14141285e-01, -1.76825166e-01,\n",
       "          6.23133779e-03,  1.02085322e-01,  1.11764133e-01,\n",
       "         -8.51048529e-02],\n",
       "        [ 2.33076662e-01, -1.21911868e-01, -1.15797639e-01,\n",
       "         -8.28996748e-02, -1.24640256e-01, -1.08559102e-01,\n",
       "          2.01183856e-02, -2.66512662e-01,  2.29588658e-01,\n",
       "          8.87648165e-02],\n",
       "        [-1.24646977e-01,  1.36031359e-01,  3.49735916e-02,\n",
       "          1.25202984e-01, -2.47946694e-01, -9.69378501e-02,\n",
       "         -9.83305275e-02,  2.17542797e-01,  9.62020755e-02,\n",
       "          2.37088710e-01],\n",
       "        [-3.03242803e-02, -6.75505102e-02,  3.18419933e-03,\n",
       "         -1.37328655e-01,  8.38300586e-03,  8.06657374e-02,\n",
       "          1.08427465e-01, -2.05167681e-01,  2.48706967e-01,\n",
       "          2.76065797e-01],\n",
       "        [-1.63757801e-02, -1.04339257e-01, -1.75678447e-01,\n",
       "         -8.79348069e-02, -1.17642313e-01,  2.30964035e-01,\n",
       "         -1.13712564e-01,  2.33358443e-02,  7.84892142e-02,\n",
       "          1.95939332e-01],\n",
       "        [-2.55098879e-01, -4.22320962e-02, -3.60245854e-02,\n",
       "          1.27136409e-02, -2.44473904e-01,  1.67675465e-01,\n",
       "          5.89684546e-02, -6.52944148e-02,  8.15716386e-02,\n",
       "         -6.17762059e-02],\n",
       "        [ 6.21573329e-02,  8.86496902e-03, -1.50808096e-01,\n",
       "         -1.84394926e-01, -1.30996853e-01,  1.01099581e-01,\n",
       "         -1.32971466e-01, -1.77779466e-01,  8.76986384e-02,\n",
       "          4.38374281e-03],\n",
       "        [ 2.42636204e-02,  1.43014103e-01, -1.11711532e-01,\n",
       "          2.57690221e-01,  2.95099616e-02, -2.37516150e-01,\n",
       "         -1.99617490e-01, -2.21986592e-01, -2.91590989e-02,\n",
       "         -9.28917974e-02],\n",
       "        [ 5.37961125e-02,  2.23270506e-01, -1.00190490e-01,\n",
       "          6.13823235e-02,  8.86167586e-02,  2.20273167e-01,\n",
       "          2.31217146e-02,  2.04306722e-01,  2.76697427e-01,\n",
       "         -1.22290820e-01],\n",
       "        [ 1.97996825e-01,  2.81752378e-01,  2.16756076e-01,\n",
       "          1.00819349e-01, -9.28199291e-03,  1.90718263e-01,\n",
       "         -1.82981402e-01,  1.02152348e-01, -3.33976150e-02,\n",
       "         -1.91356748e-01],\n",
       "        [ 1.03982627e-01,  2.37930268e-01, -5.91106713e-02,\n",
       "         -1.08393729e-02,  2.45535403e-01,  7.17424452e-02,\n",
       "         -4.14054096e-02, -1.54597461e-01,  1.54439539e-01,\n",
       "         -1.58906788e-01],\n",
       "        [ 1.69108212e-01, -3.58468294e-03,  2.69308537e-01,\n",
       "          8.06152821e-02, -8.78430307e-02, -2.10869014e-02,\n",
       "         -1.48345903e-01,  1.80472970e-01, -2.64329612e-01,\n",
       "         -1.74953789e-01],\n",
       "        [-1.55667186e-01,  1.68216765e-01, -1.52252018e-02,\n",
       "         -2.26697832e-01,  1.05053574e-01,  2.29527920e-01,\n",
       "          2.47014552e-01,  1.18505865e-01,  2.01640308e-01,\n",
       "          1.86628938e-01],\n",
       "        [ 8.21699500e-02, -2.21837640e-01,  1.31478578e-01,\n",
       "         -2.36815870e-01,  2.65158623e-01, -1.15174681e-01,\n",
       "          1.33817017e-01,  5.22322953e-02,  1.04717731e-01,\n",
       "         -1.84643671e-01],\n",
       "        [ 2.45524436e-01, -1.70830339e-01, -1.02123559e-01,\n",
       "          1.50494307e-01,  1.98805630e-02, -3.09422016e-02,\n",
       "         -2.62758136e-03,  4.09632921e-04,  2.30234534e-01,\n",
       "          2.49570101e-01],\n",
       "        [-1.71888202e-01,  2.12623745e-01,  3.73569131e-02,\n",
       "         -9.95030999e-02,  2.33181626e-01,  6.96135759e-02,\n",
       "          2.61589438e-01,  2.55183011e-01, -2.49234691e-01,\n",
       "         -1.17203549e-01],\n",
       "        [-2.54980952e-01, -2.51928866e-02,  2.22075313e-01,\n",
       "         -2.90127397e-02, -8.28198493e-02,  1.98362827e-01,\n",
       "         -2.10527062e-01, -2.81432927e-01, -1.43605947e-01,\n",
       "         -1.44766450e-01],\n",
       "        [-2.83416957e-01,  3.04666162e-03,  2.57713288e-01,\n",
       "          1.10386878e-01,  2.92085111e-02,  6.65883124e-02,\n",
       "          1.40461743e-01, -1.00528702e-01, -1.00559324e-01,\n",
       "         -1.49762273e-01],\n",
       "        [ 6.16956055e-02, -2.50618070e-01,  2.74733573e-01,\n",
       "         -2.61170745e-01,  6.80655241e-02, -9.12164301e-02,\n",
       "         -1.68034747e-01, -1.74270838e-01, -2.00530887e-03,\n",
       "         -1.66060120e-01],\n",
       "        [ 2.79113621e-01, -4.75919992e-02, -2.15631694e-01,\n",
       "         -2.56364197e-01, -3.23943496e-02,  2.25032002e-01,\n",
       "          1.76166594e-02, -7.30489790e-02,  1.36913657e-01,\n",
       "         -1.71482697e-01],\n",
       "        [-8.17146897e-03,  1.81976050e-01, -6.31843507e-02,\n",
       "         -1.81611136e-01, -1.61608234e-01, -2.12819606e-01,\n",
       "         -1.47797629e-01,  4.01849747e-02,  2.62614518e-01,\n",
       "          2.71387726e-01],\n",
       "        [-4.62850034e-02,  5.60049415e-02, -2.98457444e-02,\n",
       "          6.70764446e-02, -1.04937226e-01, -2.16089681e-01,\n",
       "         -9.18490887e-02,  2.64317393e-02, -1.86581284e-01,\n",
       "         -1.77828670e-02],\n",
       "        [ 1.78831339e-01,  1.44201010e-01, -9.00428295e-02,\n",
       "          4.27416563e-02, -4.05900627e-02,  7.80860186e-02,\n",
       "         -2.53915787e-04,  1.03599876e-01, -1.92397207e-01,\n",
       "          2.15663403e-01],\n",
       "        [ 4.87098098e-03, -2.59532511e-01,  2.69869894e-01,\n",
       "          1.22682959e-01,  7.31111765e-02, -5.28579503e-02,\n",
       "         -2.39803940e-01, -2.49874204e-01, -5.33202738e-02,\n",
       "         -7.93638080e-02],\n",
       "        [-1.93856686e-01, -1.11390144e-01,  7.38339722e-02,\n",
       "          5.02713025e-02,  2.71515518e-01,  2.67704934e-01,\n",
       "          1.09652728e-01, -7.55950809e-03,  2.84474820e-01,\n",
       "         -9.21596140e-02],\n",
       "        [-2.09752038e-01, -1.40817136e-01, -4.37157452e-02,\n",
       "          1.65248364e-01,  1.48575217e-01,  6.64430857e-03,\n",
       "          1.05141103e-01, -1.82038099e-01,  1.41739219e-01,\n",
       "         -2.27598578e-01],\n",
       "        [ 2.48257786e-01,  1.33932382e-01,  1.68173373e-01,\n",
       "          4.39285636e-02,  1.02176994e-01,  2.08757997e-01,\n",
       "         -6.93494231e-02,  1.80747032e-01,  2.45073348e-01,\n",
       "         -1.54581234e-01],\n",
       "        [-4.01728153e-02, -9.27053690e-02,  7.20254779e-02,\n",
       "          1.39364302e-01, -1.71021596e-01,  1.76769346e-01,\n",
       "         -4.56240773e-03,  7.19010830e-04, -1.56160131e-01,\n",
       "         -8.66242051e-02],\n",
       "        [-2.56964684e-01, -8.19772035e-02, -2.56064743e-01,\n",
       "          2.58569032e-01, -1.22308746e-01, -2.10440159e-01,\n",
       "         -2.84614384e-01,  1.84671700e-01,  2.83799976e-01,\n",
       "         -2.19868392e-01],\n",
       "        [-2.55671799e-01,  4.41805124e-02, -2.64383942e-01,\n",
       "          9.56007838e-02, -1.16914749e-01,  2.04429865e-01,\n",
       "          4.28081453e-02,  8.10456276e-02, -9.78939384e-02,\n",
       "         -1.28529623e-01],\n",
       "        [-5.44056892e-02, -6.51612878e-02, -1.01218060e-01,\n",
       "          9.86698270e-02, -9.34307724e-02,  8.57293606e-02,\n",
       "         -2.49201968e-01,  2.71733731e-01, -2.42698789e-02,\n",
       "         -3.21809947e-02],\n",
       "        [-8.92164260e-02, -9.48126465e-02, -7.58576095e-02,\n",
       "          1.57426208e-01,  1.87499702e-01,  1.05359614e-01,\n",
       "          1.72051936e-01,  3.93873453e-03, -1.00451171e-01,\n",
       "          8.19630027e-02],\n",
       "        [ 1.10969692e-01,  2.61483341e-01,  1.36851877e-01,\n",
       "         -2.17228651e-01, -1.69693619e-01,  1.48229659e-01,\n",
       "          8.55120420e-02, -2.28705034e-01, -1.33816138e-01,\n",
       "         -1.77404583e-01],\n",
       "        [ 7.94526041e-02,  2.11275071e-01, -6.10348582e-02,\n",
       "         -6.93613142e-02,  1.90597475e-01, -1.70801640e-01,\n",
       "          1.67971253e-02,  2.09811091e-01,  5.56822717e-02,\n",
       "         -7.83686340e-02],\n",
       "        [-1.96795002e-01, -2.07748085e-01, -2.82091290e-01,\n",
       "         -2.34973982e-01, -1.46899447e-01,  1.34043694e-02,\n",
       "         -9.40812081e-02, -1.93385124e-01,  9.78755951e-03,\n",
       "          6.36972487e-02],\n",
       "        [-2.08460927e-01,  2.18401700e-01, -5.05868644e-02,\n",
       "          2.48186916e-01,  1.18790805e-01, -2.36119628e-02,\n",
       "         -1.88169479e-02,  1.30807102e-01, -2.32727125e-01,\n",
       "         -1.87656179e-01],\n",
       "        [-3.08374465e-02, -1.87188625e-01, -2.54894793e-01,\n",
       "          1.13700539e-01, -1.47055730e-01,  7.41855204e-02,\n",
       "         -1.55916750e-01,  2.73239464e-01,  8.36414397e-02,\n",
       "          1.71205848e-01],\n",
       "        [-1.38148353e-01,  1.58344120e-01,  1.45062923e-01,\n",
       "          2.14287162e-01,  1.51432276e-01,  2.60952681e-01,\n",
       "         -2.62118071e-01,  9.39890742e-03,  1.30284607e-01,\n",
       "          2.47100621e-01],\n",
       "        [ 2.37170368e-01,  2.57988364e-01,  1.77845806e-01,\n",
       "          4.83967662e-02,  1.76729918e-01,  1.10847563e-01,\n",
       "         -1.25596881e-01,  1.69022590e-01,  1.09686941e-01,\n",
       "          7.07197785e-02],\n",
       "        [-1.66513354e-01, -1.88352644e-01,  1.44690335e-01,\n",
       "         -2.42600843e-01, -1.51269004e-01,  2.66446143e-01,\n",
       "          2.15955108e-01,  1.31531656e-02,  2.40712494e-01,\n",
       "          1.94317043e-01],\n",
       "        [-1.77009955e-01, -1.77247763e-01, -2.29717121e-01,\n",
       "          5.54734468e-03,  1.44760817e-01,  2.76894718e-01,\n",
       "          1.08104795e-01,  2.66510516e-01,  8.67465436e-02,\n",
       "          2.13410795e-01],\n",
       "        [ 1.04292274e-01, -2.32685298e-01, -1.50555819e-01,\n",
       "          1.80392385e-01, -1.82985544e-01,  9.31242406e-02,\n",
       "         -1.05755419e-01, -1.65651083e-01, -2.69738615e-01,\n",
       "         -2.33479202e-01],\n",
       "        [-1.35581255e-01, -1.22059926e-01,  2.74535745e-01,\n",
       "         -1.12918466e-01,  5.20174205e-02, -8.69236737e-02,\n",
       "         -2.44121075e-01, -2.14151725e-01, -1.26091108e-01,\n",
       "          1.56767368e-02],\n",
       "        [ 8.75075161e-02,  1.55256331e-01,  1.97781891e-01,\n",
       "          2.08149999e-01, -4.55443263e-02, -4.77887392e-02,\n",
       "         -9.28773433e-02,  7.83161521e-02, -4.11285609e-02,\n",
       "          2.24140257e-01],\n",
       "        [-2.65145659e-01,  6.09486401e-02,  1.13979220e-01,\n",
       "          1.70949966e-01,  1.55034602e-01, -2.80298948e-01,\n",
       "         -2.21479863e-01, -5.88985831e-02,  1.11412108e-02,\n",
       "          2.24376768e-01],\n",
       "        [-1.63316727e-02, -2.73377657e-01, -2.17459753e-01,\n",
       "          1.03490829e-01,  2.27100551e-02,  1.03205830e-01,\n",
       "          2.36204475e-01,  2.11506099e-01, -1.28329217e-01,\n",
       "          1.76513493e-01],\n",
       "        [-1.43066436e-01, -1.47600681e-01,  1.79847986e-01,\n",
       "          1.32959038e-01,  8.05162191e-02, -1.82485580e-03,\n",
       "         -2.44475320e-01,  2.03466743e-01,  1.04616433e-01,\n",
       "          1.78212821e-02],\n",
       "        [ 2.25124687e-01, -7.03907013e-03, -1.34811267e-01,\n",
       "         -4.76858318e-02, -2.19004095e-01,  4.56422269e-02,\n",
       "          6.40793443e-02,  1.54697597e-02,  9.29197669e-03,\n",
       "         -1.57556742e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3590b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00aa33",
   "metadata": {},
   "source": [
    "# Naming models and layers with the name argument 取名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f10e607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c70911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcda1620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691b2a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36da6f",
   "metadata": {},
   "source": [
    "# A simple Functional model with two Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11386f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274e1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b72209c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7507757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6054b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15856532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e17f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d6bf2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591e2f9",
   "metadata": {},
   "source": [
    "# Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2da270ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93b754",
   "metadata": {},
   "source": [
    "# Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cee6a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 12ms/step - loss: 38.0075 - priority_loss: 0.3196 - department_loss: 37.6879 - priority_mean_absolute_error: 0.4848 - department_accuracy: 0.2430\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 28.0195 - priority_loss: 0.3241 - department_loss: 27.6953 - priority_mean_absolute_error: 0.4890 - department_accuracy: 0.5414\n",
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705aab4",
   "metadata": {},
   "source": [
    "# Training a model by providing dicts of input & target arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3c90b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 12ms/step - loss: 47.0608 - priority_loss: 0.3241 - department_loss: 46.7367 - priority_mean_absolute_error: 0.4890 - department_accuracy: 0.2914\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 36.4289 - priority_loss: 0.3241 - department_loss: 36.1048 - priority_mean_absolute_error: 0.4890 - department_accuracy: 0.2773\n",
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26363704",
   "metadata": {},
   "source": [
    "# the inputs or outputs of a layer in a Functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f9a6f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1f22f1128b0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x1f22f112910>,\n",
       " <keras.engine.input_layer.InputLayer at 0x1f22f1128e0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x1f22f10d880>,\n",
       " <keras.layers.core.dense.Dense at 0x1f22f0fe5b0>,\n",
       " <keras.layers.core.dense.Dense at 0x1f22f0f3970>,\n",
       " <keras.layers.core.dense.Dense at 0x1f22f11f0d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f94dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08adc9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ed897",
   "metadata": {},
   "source": [
    "# Creating a new model by reusing intermediate layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330996c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fa4ec",
   "metadata": {},
   "source": [
    "# A simple subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0fb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bad84c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "206a48bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 12ms/step - loss: 32.7270 - output_1_loss: 0.3197 - output_2_loss: 32.4072 - output_1_mean_absolute_error: 0.4846 - output_2_accuracy: 0.2797\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.2723 - output_1_loss: 0.3241 - output_2_loss: 13.9482 - output_1_mean_absolute_error: 0.4890 - output_2_accuracy: 0.6164\n",
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e9b8b",
   "metadata": {},
   "source": [
    "# Creating a Functional model that includes a subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7ef04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6c928",
   "metadata": {},
   "source": [
    "# Creating a subclassed model that includes a Functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74682d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867ae78",
   "metadata": {},
   "source": [
    "# The standard workflow: compile(), fit(), evaluate(), predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6393977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2995 - accuracy: 0.9117 - val_loss: 0.1452 - val_accuracy: 0.9568\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1641 - accuracy: 0.9542 - val_loss: 0.1222 - val_accuracy: 0.9685\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1390 - accuracy: 0.9623 - val_loss: 0.1159 - val_accuracy: 0.9695\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9715\n",
      "313/313 [==============================] - 0s 863us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f2af0",
   "metadata": {},
   "source": [
    "# Writing own metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cedfeb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59f86122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2938 - accuracy: 0.9124 - rmse: 7.1857 - val_loss: 0.1619 - val_accuracy: 0.9543 - val_rmse: 7.3484\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1627 - accuracy: 0.9538 - rmse: 7.3567 - val_loss: 0.1281 - val_accuracy: 0.9660 - val_rmse: 7.4025\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1420 - accuracy: 0.9623 - rmse: 7.3885 - val_loss: 0.1174 - val_accuracy: 0.9698 - val_rmse: 7.4192\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9732 - rmse: 7.4340\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd80935",
   "metadata": {},
   "source": [
    "# Using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52868f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2990 - accuracy: 0.9122 - val_loss: 0.1514 - val_accuracy: 0.9576\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1653 - accuracy: 0.9537 - val_loss: 0.1151 - val_accuracy: 0.9681\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1393 - accuracy: 0.9631 - val_loss: 0.1236 - val_accuracy: 0.9687\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1244 - accuracy: 0.9678 - val_loss: 0.1142 - val_accuracy: 0.9734\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1165 - accuracy: 0.9698 - val_loss: 0.1061 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1148 - accuracy: 0.9716 - val_loss: 0.1045 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1049 - accuracy: 0.9753 - val_loss: 0.1155 - val_accuracy: 0.9761\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0993 - accuracy: 0.9766 - val_loss: 0.1205 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0983 - accuracy: 0.9774 - val_loss: 0.1106 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0946 - accuracy: 0.9786 - val_loss: 0.1119 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f23818fd00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9222169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc2cd7",
   "metadata": {},
   "source": [
    "# Creating a custom callback by subclassing the Callback class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f23bb8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f5674bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2955 - accuracy: 0.9121 - val_loss: 0.1487 - val_accuracy: 0.9566\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1634 - accuracy: 0.9539 - val_loss: 0.1216 - val_accuracy: 0.9679\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1385 - accuracy: 0.9631 - val_loss: 0.1177 - val_accuracy: 0.9691\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1249 - accuracy: 0.9672 - val_loss: 0.1074 - val_accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1177 - accuracy: 0.9706 - val_loss: 0.1028 - val_accuracy: 0.9767\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1085 - accuracy: 0.9729 - val_loss: 0.1073 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1054 - accuracy: 0.9744 - val_loss: 0.1167 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0995 - accuracy: 0.9772 - val_loss: 0.1066 - val_accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0973 - accuracy: 0.9776 - val_loss: 0.1044 - val_accuracy: 0.9780\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0974 - accuracy: 0.9784 - val_loss: 0.1087 - val_accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f23a3e1f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f095d2",
   "metadata": {},
   "source": [
    "# Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e86d339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2924 - accuracy: 0.9137 - val_loss: 0.1550 - val_accuracy: 0.9534\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1658 - accuracy: 0.9531 - val_loss: 0.1207 - val_accuracy: 0.9680\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1404 - accuracy: 0.9616 - val_loss: 0.1177 - val_accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1229 - accuracy: 0.9681 - val_loss: 0.1289 - val_accuracy: 0.9705\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1160 - accuracy: 0.9710 - val_loss: 0.1174 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1108 - accuracy: 0.9730 - val_loss: 0.1087 - val_accuracy: 0.9762\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1068 - accuracy: 0.9755 - val_loss: 0.1137 - val_accuracy: 0.9752\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0983 - accuracy: 0.9773 - val_loss: 0.1169 - val_accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0979 - accuracy: 0.9780 - val_loss: 0.1303 - val_accuracy: 0.9756\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0925 - accuracy: 0.9791 - val_loss: 0.1297 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f237c26f10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42beca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e3cb09d0dfc2725b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e3cb09d0dfc2725b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea6eb5",
   "metadata": {},
   "source": [
    "# Writing own training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "640b57d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e6319c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942822e",
   "metadata": {},
   "source": [
    "# A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c59ecd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85355172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf23a6",
   "metadata": {},
   "source": [
    "# Writing a step-by-step training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67f2d1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9155\n",
      "...loss: 0.2897\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9539\n",
      "...loss: 0.1657\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9633\n",
      "...loss: 0.1389\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff3ee70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9680\n",
      "...val_loss: 0.1278\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ea336",
   "metadata": {},
   "source": [
    "# Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99ee60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9680\n",
      "...val_loss: 0.1278\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99e7ac",
   "metadata": {},
   "source": [
    "# Implementing a custom training step to use with fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e573d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5864f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2948\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1666\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2376e2250>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d57b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4413d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.9128\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1619 - sparse_categorical_accuracy: 0.9545\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f23ad13d90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
