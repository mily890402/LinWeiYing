{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16370443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8133f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28),\n",
       " 60000,\n",
       " array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n",
       " (10000, 28, 28),\n",
       " 10000,\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the MNIST datasetin Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape, len(train_labels), train_labels, test_images.shape, len(test_labels), test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe479108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  47, 156, 205,\n",
       "        254, 255, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  53, 208, 245, 253, 253,\n",
       "        253, 240, 249,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,  73, 242, 248, 212, 128,  56,\n",
       "         56, 122, 253,  94,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 101, 253, 211,  64,   0,   0,   0,\n",
       "          0,  66, 253, 212,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 126, 143,  15,   0,   0,   0,   0,\n",
       "          0,  66, 253, 226,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 115, 253, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         32, 254, 253, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
       "        129, 254, 253, 252, 244,  95,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 120,\n",
       "        253, 254, 238, 225, 253, 246,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 243,\n",
       "        218,  66,  32,   3, 121, 253, 175,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116,\n",
       "         60,   0,   0,   0,   0, 236, 247,  47,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 103, 253, 135,   2,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  28, 230, 253,  47,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 113, 253, 103,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  97, 243, 237,  14,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   2,  19,  15,   0,\n",
       "          0,   0,   0,   0,   6, 184, 251, 155,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  86, 253, 236,  26,\n",
       "          0,   0,   0,  35, 169, 253, 167,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  53, 236, 253,  79,\n",
       "          0,  96, 199, 248, 253, 169,  22,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  89, 252, 249,\n",
       "        216, 240, 248, 221, 103,  17,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 239,\n",
       "        253, 170,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Visualization 查看第30000張\n",
    "x= train_images[30000]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3835d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 47156205254255112  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 53208245253253253240249 50  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  1 73242248212128 56 56122253 94  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0101253211 64  0  0  0  0 66253212  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0126143 15  0  0  0  0  0 66253226  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0115253142  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 32254253119  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  7129254253252244 95  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0120253254238225253246 50  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 42243218 66 32  3121253175  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0116 60  0  0  0  0236247 47  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0103253135  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28230253 47  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0113253103  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 97243237 14  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  2 19 15  0  0  0  0  0  6184251155  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 86253236 26  0  0  0 35169253167  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 53236253 79  0 96199248253169 22  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 89252249216240248221103 17  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 84239253170 56  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "x= train_images[30000]\n",
    "#%%\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        z= x[i,j]\n",
    "        print(f'{z:3d}', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b38345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15384aaec70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "pl.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef66f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[30000]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 3\n"
     ]
    }
   ],
   "source": [
    "y= train_labels[30000]\n",
    "print(f'{y = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c09b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the image data\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead25fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 3ms/step - loss: 6.0970 - accuracy: 0.1502\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 5.8290 - accuracy: 0.1964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.828952789306641, 0.1964000016450882]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512),\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# \"Fitting\" the model\n",
    "\n",
    "my_model.fit(train_images, train_labels)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1325ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2143/2143 [==============================] - 9s 4ms/step - loss: 4.8275 - accuracy: 0.1128\n",
      "Epoch 2/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.7350 - accuracy: 0.1248\n",
      "Epoch 3/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.6212 - accuracy: 0.1489\n",
      "Epoch 4/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.6085 - accuracy: 0.1520\n",
      "Epoch 5/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.6229 - accuracy: 0.1488\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 4.4788 - accuracy: 0.1822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.47876501083374, 0.18223333358764648]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "# 看看加一層 Dense(128, activation=\"relu\") 和 epochs=5, batch_size=28 會如何\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\")\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=5, batch_size=28)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b82d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.2108 - accuracy: 0.9383\n",
      "Epoch 2/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.0936 - accuracy: 0.9725\n",
      "Epoch 3/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.0684 - accuracy: 0.9811\n",
      "Epoch 4/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.0552 - accuracy: 0.9850\n",
      "Epoch 5/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.0433 - accuracy: 0.9881\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0318 - accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03177785873413086, 0.991100013256073]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "# 看看加一層 Dense(100, activation=\"softmax\") 和 epochs=5, batch_size=28 會如何\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=5, batch_size=28)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c241e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8846\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9437\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1453 - accuracy: 0.9570\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1199 - accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9736\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9791\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9789\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9811\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.0326 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03257378935813904, 0.9906666874885559]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "# 看看 input_shape=(28*28,) 和 epochs=10, batch_size=128, Dropout(0.2) 會如何\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\",input_shape=(28*28,)),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(10,  activation= 'softmax')\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb9b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "[9.5387485e-09 1.7427446e-08 6.2089334e-06 2.4748856e-04 6.9996994e-11\n",
      " 1.3434952e-07 2.0048947e-13 9.9972492e-01 2.3671495e-07 2.1028924e-05]\n",
      "7\n",
      "0.9997249\n",
      "7\n",
      "313/313 [==============================] - 0s 784us/step - loss: 0.0690 - accuracy: 0.9784\n",
      "test_acc: 0.9783999919891357\n"
     ]
    }
   ],
   "source": [
    "# Using the model to make predictions\n",
    "\n",
    "test_digits = test_images[0:10]\n",
    "predictions = my_model.predict(test_digits)\n",
    "print(predictions[0])\n",
    "print(predictions[0].argmax())\n",
    "print(predictions[0][7])\n",
    "print(test_labels[0])\n",
    "\n",
    "# Evaluating the model on new data\n",
    "\n",
    "test_loss, test_acc = my_model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516ac470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data representations for neural networks\n",
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e94c912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectors\n",
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b89242b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[ 5 78  2]\n",
      " [34  0  6]\n",
      " [79  3 35]\n",
      " [ 1  7 80]\n",
      " [ 4 36  2]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Matrices\n",
    "x = np.array([[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]])\n",
    "print(x.ndim)\n",
    "x1 = x.reshape(5,3)\n",
    "print(x1)\n",
    "print(x1.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71729345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank-3 and higher-rank tensors\n",
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]],\n",
    " [[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]],\n",
    " [[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]]])\n",
    "x.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e92f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n",
      "47040000\n",
      "47040000\n"
     ]
    }
   ],
   "source": [
    "# Key attributes\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.ndim)\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)\n",
    "print(train_images.size)\n",
    "print(train_images.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56cefb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Manipulating tensors in NumPy\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4467852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The fourth sample in our dataset\n",
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ff3012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bd1af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[240, 253, 253, ...,   0,   0,   0],\n",
       "        [ 45, 186, 253, ...,   0,   0,   0],\n",
       "        [  0,  16,  93, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[241, 243, 234, ...,   0,   0,   0],\n",
       "        [143,  91,  28, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[253, 254, 253, ...,   0,   0,   0],\n",
       "        [ 72, 192, 254, ...,   0,   0,   0],\n",
       "        [  0,   6, 242, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,  31, 127, ...,   0,   0,   0],\n",
       "        [ 27, 218, 252, ...,   0,   0,   0],\n",
       "        [194, 253, 217, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[ 97, 254, 252, ...,   0,   0,   0],\n",
       "        [232, 181,  60, ...,   0,   0,   0],\n",
       "        [ 46,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "my_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b90ee869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 49, 238, 253, ...,  93,  82,  82],\n",
       "        [ 18, 219, 253, ...,   0,   0,   0],\n",
       "        [  0,  80, 156, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 253, 207,   2],\n",
       "        [  0,   0,   0, ..., 250, 182,   0],\n",
       "        [  0,   0,   0, ...,  78,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,  84, 252, 253],\n",
       "        [  0,   0,   0, ...,  96, 189, 253],\n",
       "        [  0,   0,   0, ...,  47,  79, 255],\n",
       "        ...,\n",
       "        [252, 145,   0, ..., 252, 173,   0],\n",
       "        [253, 225,   0, ..., 162,   0,   0],\n",
       "        [252, 249, 146, ...,  56,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,   0,   2, 153],\n",
       "        [  0,   0,   0, ...,   0,  27, 254],\n",
       "        [  0,   0,   0, ...,   0, 183, 254],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 254,  57,   0],\n",
       "        [  0,   0,   0, ..., 254,  57,   0],\n",
       "        [  0,   0,   0, ..., 255,  94,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0, ..., 223, 159, 131],\n",
       "        [  0,   0,   0, ...,  27,   0,   0],\n",
       "        [  0,   0,  54, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 173,   0,   0],\n",
       "        [  0,   0,   0, ..., 173,   0,   0],\n",
       "        [  0,   0,   0, ...,  74,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [247, 110,   0, ..., 146, 163,  63],\n",
       "        [236, 128,   0, ..., 178,  12,   0],\n",
       "        [239, 196, 169, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ..., 254, 212,  27],\n",
       "        [  0,   0,   0, ..., 218, 237, 248],\n",
       "        [  0,   0,   0, ...,   0,  92, 231],\n",
       "        ...,\n",
       "        [  0, 110, 254, ...,   0,   0,   0],\n",
       "        [131, 254, 154, ...,   0,   0,   0],\n",
       "        [209, 153,  19, ...,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7702b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# The notion of data batches\n",
    "batch = train_images[:128]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae410659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "batch = train_images[128:256]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d1817f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db5ba17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3f629da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "052c6205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.00 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3dc8851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f77b2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting\n",
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed5c8b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(y, axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdd389dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917],\n",
       "       [0.53263933, 0.43944265, 0.69845406, 0.91099923, 0.26571768,\n",
       "        0.56661966, 0.25139079, 0.34141035, 0.7487109 , 0.86949917]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "197f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21a72676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.95494392, 0.96996137, 0.78787691, ..., 0.69625413,\n",
       "          0.35598434, 0.35551498],\n",
       "         [0.5518776 , 0.27986746, 0.91480779, ..., 0.41076664,\n",
       "          0.24442082, 0.57013527],\n",
       "         [0.32064494, 0.99697936, 0.05317933, ..., 0.98055315,\n",
       "          0.85522805, 0.79298112],\n",
       "         ...,\n",
       "         [0.73343893, 0.35139485, 0.68174926, ..., 0.98288598,\n",
       "          0.89788266, 0.80739818],\n",
       "         [0.81019052, 0.19254295, 0.41179857, ..., 0.27369464,\n",
       "          0.04707287, 0.87309147],\n",
       "         [0.15209667, 0.53311145, 0.50513032, ..., 0.30195765,\n",
       "          0.69979543, 0.32822888]],\n",
       "\n",
       "        [[0.74556037, 0.59265583, 0.78787691, ..., 0.95667302,\n",
       "          0.35598434, 0.35551498],\n",
       "         [0.5518776 , 0.57227844, 0.91480779, ..., 0.44209799,\n",
       "          0.42417429, 0.29992425],\n",
       "         [0.93590197, 0.94585209, 0.02954048, ..., 0.40026469,\n",
       "          0.83617336, 0.22682594],\n",
       "         ...,\n",
       "         [0.66961308, 0.35139485, 0.69222498, ..., 0.98288598,\n",
       "          0.67142769, 0.80739818],\n",
       "         [0.77186991, 0.54158001, 0.50122231, ..., 0.66852037,\n",
       "          0.05310072, 0.87309147],\n",
       "         [0.04139536, 0.53311145, 0.50513032, ..., 0.29955335,\n",
       "          0.80875429, 0.32822888]],\n",
       "\n",
       "        [[0.74556037, 0.77612322, 0.89034421, ..., 0.87738454,\n",
       "          0.77581562, 0.42422338],\n",
       "         [0.8569435 , 0.4147816 , 0.91480779, ..., 0.30192118,\n",
       "          0.18659307, 0.50769079],\n",
       "         [0.74462429, 0.94585209, 0.99165833, ..., 0.94892311,\n",
       "          0.65340345, 0.89340267],\n",
       "         ...,\n",
       "         [0.7863837 , 0.38129888, 0.68174926, ..., 0.98288598,\n",
       "          0.20332804, 0.80739818],\n",
       "         [0.47573308, 0.19536984, 0.75488206, ..., 0.00561519,\n",
       "          0.23314337, 0.87309147],\n",
       "         [0.26470748, 0.53311145, 0.94905564, ..., 0.29955335,\n",
       "          0.38153294, 0.83751393]]],\n",
       "\n",
       "\n",
       "       [[[0.74556037, 0.75305526, 0.78787691, ..., 0.97663699,\n",
       "          0.55451814, 0.54484994],\n",
       "         [0.72436423, 0.81074982, 0.91480779, ..., 0.30266872,\n",
       "          0.26130815, 0.29992425],\n",
       "         [0.61109307, 0.94585209, 0.5228943 , ..., 0.78994948,\n",
       "          0.22776979, 0.54448979],\n",
       "         ...,\n",
       "         [0.17627705, 0.35139485, 0.68174926, ..., 0.98288598,\n",
       "          0.55865609, 0.85019377],\n",
       "         [0.47573308, 0.45263304, 0.43296762, ..., 0.24512247,\n",
       "          0.68158044, 0.87309147],\n",
       "         [0.77295553, 0.53311145, 0.50513032, ..., 0.29955335,\n",
       "          0.6893631 , 0.67865238]],\n",
       "\n",
       "        [[0.95910016, 0.59265583, 0.78787691, ..., 0.45215742,\n",
       "          0.93242196, 0.54776051],\n",
       "         [0.62946891, 0.27986746, 0.91480779, ..., 0.7073488 ,\n",
       "          0.43563981, 0.33196162],\n",
       "         [0.45182176, 0.94585209, 0.9180776 , ..., 0.81129896,\n",
       "          0.58811044, 0.60702316],\n",
       "         ...,\n",
       "         [0.80327968, 0.35139485, 0.87645709, ..., 0.98288598,\n",
       "          0.61526794, 0.80739818],\n",
       "         [0.47573308, 0.19254295, 0.88462308, ..., 0.8792278 ,\n",
       "          0.58261158, 0.87309147],\n",
       "         [0.60152381, 0.53311145, 0.50513032, ..., 0.29955335,\n",
       "          0.15715959, 0.32822888]],\n",
       "\n",
       "        [[0.74556037, 0.59265583, 0.78787691, ..., 0.73614402,\n",
       "          0.35598434, 0.40158059],\n",
       "         [0.5518776 , 0.36620186, 0.91480779, ..., 0.39403407,\n",
       "          0.24336012, 0.67914097],\n",
       "         [0.33373189, 0.94585209, 0.39921673, ..., 0.7526498 ,\n",
       "          0.93541954, 0.40350233],\n",
       "         ...,\n",
       "         [0.92761818, 0.35139485, 0.86473604, ..., 0.98288598,\n",
       "          0.75619313, 0.80739818],\n",
       "         [0.47573308, 0.93576056, 0.60851043, ..., 0.62452667,\n",
       "          0.60693319, 0.87309147],\n",
       "         [0.15921379, 0.53311145, 0.63288238, ..., 0.29955335,\n",
       "          0.84332145, 0.78959371]]],\n",
       "\n",
       "\n",
       "       [[[0.95980132, 0.59265583, 0.78787691, ..., 0.88519859,\n",
       "          0.35598434, 0.35551498],\n",
       "         [0.73626767, 0.56090128, 0.91480779, ..., 0.18562044,\n",
       "          0.35574976, 0.59404001],\n",
       "         [0.93603538, 0.94585209, 0.01174442, ..., 0.40026469,\n",
       "          0.94540585, 0.553628  ],\n",
       "         ...,\n",
       "         [0.04698846, 0.91508671, 0.68174926, ..., 0.98288598,\n",
       "          0.74865188, 0.80739818],\n",
       "         [0.47573308, 0.83908629, 0.86089502, ..., 0.12613709,\n",
       "          0.04114932, 0.87309147],\n",
       "         [0.04139536, 0.53311145, 0.99999686, ..., 0.4754803 ,\n",
       "          0.72029813, 0.32822888]],\n",
       "\n",
       "        [[0.74556037, 0.59265583, 0.78787691, ..., 0.42050541,\n",
       "          0.3900654 , 0.35551498],\n",
       "         [0.93578566, 0.27986746, 0.91480779, ..., 0.76624774,\n",
       "          0.3935882 , 0.29992425],\n",
       "         [0.32064494, 0.94585209, 0.13370644, ..., 0.40026469,\n",
       "          0.13446048, 0.81855143],\n",
       "         ...,\n",
       "         [0.72217264, 0.72423681, 0.68174926, ..., 0.98288598,\n",
       "          0.20936616, 0.80739818],\n",
       "         [0.92505021, 0.41218007, 0.47726757, ..., 0.88046908,\n",
       "          0.48993369, 0.87309147],\n",
       "         [0.34635844, 0.53311145, 0.50513032, ..., 0.29955335,\n",
       "          0.94812498, 0.58734093]],\n",
       "\n",
       "        [[0.74556037, 0.70113795, 0.78787691, ..., 0.42050541,\n",
       "          0.82125536, 0.35551498],\n",
       "         [0.5518776 , 0.57483697, 0.91480779, ..., 0.58373009,\n",
       "          0.14320638, 0.51368615],\n",
       "         [0.77454194, 0.94585209, 0.5087625 , ..., 0.40026469,\n",
       "          0.86980855, 0.22682594],\n",
       "         ...,\n",
       "         [0.95005913, 0.39639242, 0.68174926, ..., 0.98288598,\n",
       "          0.15989276, 0.80739818],\n",
       "         [0.9503947 , 0.70494831, 0.79708462, ..., 0.16642407,\n",
       "          0.58782764, 0.87309147],\n",
       "         [0.52875494, 0.53311145, 0.8333313 , ..., 0.87014543,\n",
       "          0.77224621, 0.58066657]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.74556037, 0.59265583, 0.98056012, ..., 0.43966755,\n",
       "          0.46093402, 0.35551498],\n",
       "         [0.67009112, 0.52739588, 0.92116166, ..., 0.6729467 ,\n",
       "          0.83528907, 0.77110436],\n",
       "         [0.68735004, 0.94585209, 0.94454364, ..., 0.98154795,\n",
       "          0.34244363, 0.22682594],\n",
       "         ...,\n",
       "         [0.70336978, 0.57136185, 0.68174926, ..., 0.98288598,\n",
       "          0.15989276, 0.96805066],\n",
       "         [0.47573308, 0.22014312, 0.56466268, ..., 0.35506028,\n",
       "          0.17102316, 0.87309147],\n",
       "         [0.75949191, 0.88540093, 0.50513032, ..., 0.38098941,\n",
       "          0.7614021 , 0.32822888]],\n",
       "\n",
       "        [[0.84636881, 0.59265583, 0.78787691, ..., 0.42050541,\n",
       "          0.96162437, 0.87566766],\n",
       "         [0.5518776 , 0.586698  , 0.91480779, ..., 0.92931143,\n",
       "          0.21745576, 0.88693646],\n",
       "         [0.70424272, 0.94585209, 0.33445013, ..., 0.62970289,\n",
       "          0.13446048, 0.40094205],\n",
       "         ...,\n",
       "         [0.47230944, 0.58698918, 0.85655294, ..., 0.98288598,\n",
       "          0.3236938 , 0.80739818],\n",
       "         [0.47573308, 0.55977136, 0.33694463, ..., 0.59105546,\n",
       "          0.22436333, 0.87309147],\n",
       "         [0.29808962, 0.53311145, 0.50513032, ..., 0.69809682,\n",
       "          0.61756742, 0.48500887]],\n",
       "\n",
       "        [[0.74556037, 0.81046628, 0.78787691, ..., 0.42050541,\n",
       "          0.35598434, 0.58579508],\n",
       "         [0.5518776 , 0.27986746, 0.91480779, ..., 0.96470912,\n",
       "          0.9797674 , 0.58371081],\n",
       "         [0.9867746 , 0.94585209, 0.32993791, ..., 0.40026469,\n",
       "          0.50544356, 0.5389958 ],\n",
       "         ...,\n",
       "         [0.72946349, 0.9609148 , 0.68174926, ..., 0.98288598,\n",
       "          0.45157745, 0.80739818],\n",
       "         [0.81580989, 0.72080072, 0.03862305, ..., 0.14632837,\n",
       "          0.83547042, 0.87309147],\n",
       "         [0.56575119, 0.71847285, 0.50513032, ..., 0.29955335,\n",
       "          0.11757493, 0.66166412]]],\n",
       "\n",
       "\n",
       "       [[[0.91347426, 0.93119896, 0.78787691, ..., 0.42050541,\n",
       "          0.41133341, 0.35551498],\n",
       "         [0.5518776 , 0.27986746, 0.92478   , ..., 0.16706243,\n",
       "          0.14320638, 0.29992425],\n",
       "         [0.83330486, 0.94585209, 0.96808456, ..., 0.40026469,\n",
       "          0.75586657, 0.40460583],\n",
       "         ...,\n",
       "         [0.61898095, 0.35139485, 0.68174926, ..., 0.98288598,\n",
       "          0.54352478, 0.80739818],\n",
       "         [0.83963662, 0.7790976 , 0.54784218, ..., 0.17561546,\n",
       "          0.93588766, 0.87309147],\n",
       "         [0.50868998, 0.53311145, 0.93832621, ..., 0.41652425,\n",
       "          0.93755629, 0.65421997]],\n",
       "\n",
       "        [[0.74556037, 0.59265583, 0.78787691, ..., 0.42050541,\n",
       "          0.35598434, 0.97376787],\n",
       "         [0.5518776 , 0.27986746, 0.91480779, ..., 0.45847039,\n",
       "          0.49942431, 0.672354  ],\n",
       "         [0.32064494, 0.94585209, 0.27670462, ..., 0.40026469,\n",
       "          0.1639658 , 0.22682594],\n",
       "         ...,\n",
       "         [0.47149418, 0.54199487, 0.68174926, ..., 0.98288598,\n",
       "          0.47846908, 0.80739818],\n",
       "         [0.71780227, 0.98664626, 0.02010534, ..., 0.07293613,\n",
       "          0.3135411 , 0.87309147],\n",
       "         [0.74724092, 0.53311145, 0.75078127, ..., 0.37124699,\n",
       "          0.16525191, 0.32822888]],\n",
       "\n",
       "        [[0.74556037, 0.59265583, 0.78787691, ..., 0.42050541,\n",
       "          0.86282217, 0.66739867],\n",
       "         [0.59739391, 0.8643917 , 0.91480779, ..., 0.96004162,\n",
       "          0.46668565, 0.64866585],\n",
       "         [0.32064494, 0.94585209, 0.33653599, ..., 0.40026469,\n",
       "          0.69243884, 0.99839542],\n",
       "         ...,\n",
       "         [0.89944868, 0.52657383, 0.68174926, ..., 0.98288598,\n",
       "          0.5337867 , 0.80739818],\n",
       "         [0.47573308, 0.2064424 , 0.71334035, ..., 0.36231538,\n",
       "          0.72564304, 0.87309147],\n",
       "         [0.78030079, 0.53311145, 0.92638075, ..., 0.85589596,\n",
       "          0.31241118, 0.56083028]]],\n",
       "\n",
       "\n",
       "       [[[0.74556037, 0.6174889 , 0.8950912 , ..., 0.999269  ,\n",
       "          0.38713659, 0.65894694],\n",
       "         [0.65108759, 0.63322797, 0.91480779, ..., 0.16706243,\n",
       "          0.88605122, 0.86909076],\n",
       "         [0.69000639, 0.94585209, 0.35195765, ..., 0.40026469,\n",
       "          0.52414198, 0.71773709],\n",
       "         ...,\n",
       "         [0.1660052 , 0.35139485, 0.68174926, ..., 0.98288598,\n",
       "          0.15989276, 0.92902759],\n",
       "         [0.83674058, 0.22376137, 0.44653528, ..., 0.2083097 ,\n",
       "          0.69510814, 0.87309147],\n",
       "         [0.30084877, 0.73532241, 0.50513032, ..., 0.96686818,\n",
       "          0.23445548, 0.32822888]],\n",
       "\n",
       "        [[0.84592052, 0.59265583, 0.78787691, ..., 0.80650437,\n",
       "          0.35598434, 0.35551498],\n",
       "         [0.5518776 , 0.64444554, 0.91480779, ..., 0.90761856,\n",
       "          0.46229413, 0.95794394],\n",
       "         [0.99419352, 0.94585209, 0.20186829, ..., 0.40026469,\n",
       "          0.95987194, 0.93826837],\n",
       "         ...,\n",
       "         [0.15678724, 0.91569018, 0.9824924 , ..., 0.98288598,\n",
       "          0.90361346, 0.8871982 ],\n",
       "         [0.48326056, 0.36092728, 0.84938317, ..., 0.18838586,\n",
       "          0.24763559, 0.87309147],\n",
       "         [0.39148185, 0.65609005, 0.50513032, ..., 0.31076473,\n",
       "          0.94988082, 0.60822995]],\n",
       "\n",
       "        [[0.74556037, 0.59265583, 0.98643404, ..., 0.81345213,\n",
       "          0.77426009, 0.92603488],\n",
       "         [0.5518776 , 0.47020069, 0.91480779, ..., 0.27458583,\n",
       "          0.78536899, 0.29992425],\n",
       "         [0.32064494, 0.94585209, 0.6647101 , ..., 0.86875012,\n",
       "          0.39128408, 0.80591873],\n",
       "         ...,\n",
       "         [0.06993093, 0.79173808, 0.98112276, ..., 0.98288598,\n",
       "          0.9087797 , 0.80739818],\n",
       "         [0.6465372 , 0.89478553, 0.96302842, ..., 0.07348419,\n",
       "          0.22705014, 0.87309147],\n",
       "         [0.90323888, 0.95595566, 0.50513032, ..., 0.90445762,\n",
       "          0.12148807, 0.42196829]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bc38806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.226741485469152"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor product\n",
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d21a5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc0a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cbe1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2b1ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db55b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor reshaping\n",
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbfbf0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "958755c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24803589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e62b773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking back at our first example\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30932077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27ebf47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31a34ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2538 - accuracy: 0.9258\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1037 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.9799\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0492 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15387b301f0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6762b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimplementing our first example from scratch in TensorFlow\n",
    "# A simple Dense class\n",
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "441d79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple Sequential class\n",
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "               x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights\n",
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abe0deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A batch generator\n",
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba8eebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running one training step\n",
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "337ce093",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00aecdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3925775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full training loop\n",
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00d0e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 6.18\n",
      "loss at batch 100: 2.23\n",
      "loss at batch 200: 2.20\n",
      "loss at batch 300: 2.10\n",
      "loss at batch 400: 2.23\n",
      "Epoch 1\n",
      "loss at batch 0: 1.89\n",
      "loss at batch 100: 1.85\n",
      "loss at batch 200: 1.81\n",
      "loss at batch 300: 1.71\n",
      "loss at batch 400: 1.83\n",
      "Epoch 2\n",
      "loss at batch 0: 1.55\n",
      "loss at batch 100: 1.55\n",
      "loss at batch 200: 1.47\n",
      "loss at batch 300: 1.41\n",
      "loss at batch 400: 1.51\n",
      "Epoch 3\n",
      "loss at batch 0: 1.29\n",
      "loss at batch 100: 1.31\n",
      "loss at batch 200: 1.21\n",
      "loss at batch 300: 1.19\n",
      "loss at batch 400: 1.27\n",
      "Epoch 4\n",
      "loss at batch 0: 1.10\n",
      "loss at batch 100: 1.13\n",
      "loss at batch 200: 1.02\n",
      "loss at batch 300: 1.03\n",
      "loss at batch 400: 1.10\n",
      "Epoch 5\n",
      "loss at batch 0: 0.96\n",
      "loss at batch 100: 0.99\n",
      "loss at batch 200: 0.88\n",
      "loss at batch 300: 0.92\n",
      "loss at batch 400: 0.99\n",
      "Epoch 6\n",
      "loss at batch 0: 0.85\n",
      "loss at batch 100: 0.89\n",
      "loss at batch 200: 0.78\n",
      "loss at batch 300: 0.83\n",
      "loss at batch 400: 0.90\n",
      "Epoch 7\n",
      "loss at batch 0: 0.77\n",
      "loss at batch 100: 0.81\n",
      "loss at batch 200: 0.70\n",
      "loss at batch 300: 0.76\n",
      "loss at batch 400: 0.83\n",
      "Epoch 8\n",
      "loss at batch 0: 0.71\n",
      "loss at batch 100: 0.74\n",
      "loss at batch 200: 0.65\n",
      "loss at batch 300: 0.71\n",
      "loss at batch 400: 0.78\n",
      "Epoch 9\n",
      "loss at batch 0: 0.67\n",
      "loss at batch 100: 0.69\n",
      "loss at batch 200: 0.60\n",
      "loss at batch 300: 0.66\n",
      "loss at batch 400: 0.74\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88336d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")\n",
    "\n",
    "# Summary\n",
    "print(train_images.itemsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
