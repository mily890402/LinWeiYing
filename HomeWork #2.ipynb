{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16370443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8133f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28),\n",
       " 60000,\n",
       " array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n",
       " (10000, 28, 28),\n",
       " 10000,\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the MNIST datasetin Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape, len(train_labels), train_labels, test_images.shape, len(test_labels), test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe479108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  47, 156, 205,\n",
       "        254, 255, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  53, 208, 245, 253, 253,\n",
       "        253, 240, 249,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,  73, 242, 248, 212, 128,  56,\n",
       "         56, 122, 253,  94,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 101, 253, 211,  64,   0,   0,   0,\n",
       "          0,  66, 253, 212,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 126, 143,  15,   0,   0,   0,   0,\n",
       "          0,  66, 253, 226,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 115, 253, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         32, 254, 253, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
       "        129, 254, 253, 252, 244,  95,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 120,\n",
       "        253, 254, 238, 225, 253, 246,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 243,\n",
       "        218,  66,  32,   3, 121, 253, 175,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116,\n",
       "         60,   0,   0,   0,   0, 236, 247,  47,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 103, 253, 135,   2,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  28, 230, 253,  47,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 113, 253, 103,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  97, 243, 237,  14,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   2,  19,  15,   0,\n",
       "          0,   0,   0,   0,   6, 184, 251, 155,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  86, 253, 236,  26,\n",
       "          0,   0,   0,  35, 169, 253, 167,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  53, 236, 253,  79,\n",
       "          0,  96, 199, 248, 253, 169,  22,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  89, 252, 249,\n",
       "        216, 240, 248, 221, 103,  17,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 239,\n",
       "        253, 170,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Visualization 查看第30000張\n",
    "x= train_images[30000]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3835d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 47156205254255112  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 53208245253253253240249 50  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  1 73242248212128 56 56122253 94  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0101253211 64  0  0  0  0 66253212  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0126143 15  0  0  0  0  0 66253226  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0115253142  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 32254253119  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  7129254253252244 95  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0120253254238225253246 50  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 42243218 66 32  3121253175  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0116 60  0  0  0  0236247 47  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0103253135  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28230253 47  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0113253103  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 97243237 14  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  2 19 15  0  0  0  0  0  6184251155  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 86253236 26  0  0  0 35169253167  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 53236253 79  0 96199248253169 22  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 89252249216240248221103 17  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 84239253170 56  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "x= train_images[30000]\n",
    "#%%\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        z= x[i,j]\n",
    "        print(f'{z:3d}', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b38345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1420328dc70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "pl.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef66f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[30000]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 3\n"
     ]
    }
   ],
   "source": [
    "y= train_labels[30000]\n",
    "print(f'{y = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c09b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the image data\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead25fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 6s 3ms/step - loss: 4.3381 - accuracy: 0.3555\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.9874 - accuracy: 0.3877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.9874072074890137, 0.3876666724681854]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512),\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# \"Fitting\" the model\n",
    "\n",
    "my_model.fit(train_images, train_labels)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1325ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2143/2143 [==============================] - 8s 3ms/step - loss: 4.8713 - accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.8520 - accuracy: 0.0987\n",
      "Epoch 3/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.8520 - accuracy: 0.0987\n",
      "Epoch 4/5\n",
      "2143/2143 [==============================] - 9s 4ms/step - loss: 4.8520 - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 4.8520 - accuracy: 0.0987\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 4.8520 - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.852000713348389, 0.09871666878461838]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "# 看看加一層 Dense(128, activation=\"relu\") 和 epochs=5, batch_size=28 會如何\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\")\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=5, batch_size=28)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b82d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2143/2143 [==============================] - 8s 3ms/step - loss: 1.0834 - accuracy: 0.7206\n",
      "Epoch 2/5\n",
      "2143/2143 [==============================] - 7s 3ms/step - loss: 0.3828 - accuracy: 0.8914\n",
      "Epoch 3/5\n",
      "2143/2143 [==============================] - 7s 3ms/step - loss: 0.3245 - accuracy: 0.9054\n",
      "Epoch 4/5\n",
      "2143/2143 [==============================] - 7s 3ms/step - loss: 0.2994 - accuracy: 0.9133\n",
      "Epoch 5/5\n",
      "2143/2143 [==============================] - 7s 3ms/step - loss: 0.2814 - accuracy: 0.9183\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2704 - accuracy: 0.9214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27044522762298584, 0.9213833212852478]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "# 看看加一層 Dense(100, activation=\"softmax\") 和 epochs=5, batch_size=28 會如何\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=5, batch_size=28)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf177df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.0478 - accuracy: 0.4812\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.8252 - accuracy: 0.8088\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4863 - accuracy: 0.8732\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3906 - accuracy: 0.8918\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3506 - accuracy: 0.9011\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3280 - accuracy: 0.9066\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3124 - accuracy: 0.9101\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3008 - accuracy: 0.9133\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2911 - accuracy: 0.9163\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2829 - accuracy: 0.9186\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2773 - accuracy: 0.9197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2773284614086151, 0.9197333455085754]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "# 看看加一層 Dense(100, activation=\"softmax\") 和 epochs=10, batch_size=128 會如何\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c241e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.0896 - accuracy: 0.6800\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.4432 - accuracy: 0.8702\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8978\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3106 - accuracy: 0.9092\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2814 - accuracy: 0.9180\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2544 - accuracy: 0.9255\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2307 - accuracy: 0.9327\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2098 - accuracy: 0.9395\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.1911 - accuracy: 0.9448\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.1755 - accuracy: 0.9490\n",
      "1875/1875 [==============================] - 2s 949us/step - loss: 0.1744 - accuracy: 0.9485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17435751855373383, 0.9484666585922241]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network architecture\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "my_model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(50,  activation= 'relu'), \n",
    "    keras.layers.Dense(10,  activation= 'softmax')\n",
    "])\n",
    "\n",
    "# The compilation step\n",
    "my_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# \"Fitting\" the model\n",
    "my_model.fit(train_images, train_labels, epochs=10, batch_size=100)\n",
    "my_model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffb9b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "[6.5600623e-05 4.3684056e-09 1.2256218e-04 1.1415301e-03 3.4481678e-07\n",
      " 3.1823140e-05 2.0067421e-09 9.9797183e-01 9.2835926e-06 6.5698038e-04]\n",
      "7\n",
      "0.99797183\n",
      "7\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9276\n",
      "test_acc: 0.9276000261306763\n"
     ]
    }
   ],
   "source": [
    "# Using the model to make predictions\n",
    "\n",
    "test_digits = test_images[0:10]\n",
    "predictions = my_model.predict(test_digits)\n",
    "print(predictions[0])\n",
    "print(predictions[0].argmax())\n",
    "print(predictions[0][7])\n",
    "print(test_labels[0])\n",
    "\n",
    "# Evaluating the model on new data\n",
    "\n",
    "test_loss, test_acc = my_model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "516ac470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data representations for neural networks\n",
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e94c912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectors\n",
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b89242b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[ 5 78  2]\n",
      " [34  0  6]\n",
      " [79  3 35]\n",
      " [ 1  7 80]\n",
      " [ 4 36  2]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Matrices\n",
    "x = np.array([[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]])\n",
    "print(x.ndim)\n",
    "x1 = x.reshape(5,3)\n",
    "print(x1)\n",
    "print(x1.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71729345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank-3 and higher-rank tensors\n",
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]],\n",
    " [[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]],\n",
    " [[5, 78, 2, 34, 0],\n",
    " [6, 79, 3, 35, 1],\n",
    " [7, 80, 4, 36, 2]]])\n",
    "x.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e92f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n",
      "47040000\n",
      "47040000\n"
     ]
    }
   ],
   "source": [
    "# Key attributes\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.ndim)\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)\n",
    "print(train_images.size)\n",
    "print(train_images.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56cefb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Manipulating tensors in NumPy\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4467852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The fourth sample in our dataset\n",
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6ff3012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bd1af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[240, 253, 253, ...,   0,   0,   0],\n",
       "        [ 45, 186, 253, ...,   0,   0,   0],\n",
       "        [  0,  16,  93, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[241, 243, 234, ...,   0,   0,   0],\n",
       "        [143,  91,  28, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[253, 254, 253, ...,   0,   0,   0],\n",
       "        [ 72, 192, 254, ...,   0,   0,   0],\n",
       "        [  0,   6, 242, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,  31, 127, ...,   0,   0,   0],\n",
       "        [ 27, 218, 252, ...,   0,   0,   0],\n",
       "        [194, 253, 217, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[ 97, 254, 252, ...,   0,   0,   0],\n",
       "        [232, 181,  60, ...,   0,   0,   0],\n",
       "        [ 46,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "my_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b90ee869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 49, 238, 253, ...,  93,  82,  82],\n",
       "        [ 18, 219, 253, ...,   0,   0,   0],\n",
       "        [  0,  80, 156, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 253, 207,   2],\n",
       "        [  0,   0,   0, ..., 250, 182,   0],\n",
       "        [  0,   0,   0, ...,  78,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,  84, 252, 253],\n",
       "        [  0,   0,   0, ...,  96, 189, 253],\n",
       "        [  0,   0,   0, ...,  47,  79, 255],\n",
       "        ...,\n",
       "        [252, 145,   0, ..., 252, 173,   0],\n",
       "        [253, 225,   0, ..., 162,   0,   0],\n",
       "        [252, 249, 146, ...,  56,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,   0,   2, 153],\n",
       "        [  0,   0,   0, ...,   0,  27, 254],\n",
       "        [  0,   0,   0, ...,   0, 183, 254],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 254,  57,   0],\n",
       "        [  0,   0,   0, ..., 254,  57,   0],\n",
       "        [  0,   0,   0, ..., 255,  94,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0, ..., 223, 159, 131],\n",
       "        [  0,   0,   0, ...,  27,   0,   0],\n",
       "        [  0,   0,  54, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 173,   0,   0],\n",
       "        [  0,   0,   0, ..., 173,   0,   0],\n",
       "        [  0,   0,   0, ...,  74,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [247, 110,   0, ..., 146, 163,  63],\n",
       "        [236, 128,   0, ..., 178,  12,   0],\n",
       "        [239, 196, 169, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0, ..., 254, 212,  27],\n",
       "        [  0,   0,   0, ..., 218, 237, 248],\n",
       "        [  0,   0,   0, ...,   0,  92, 231],\n",
       "        ...,\n",
       "        [  0, 110, 254, ...,   0,   0,   0],\n",
       "        [131, 254, 154, ...,   0,   0,   0],\n",
       "        [209, 153,  19, ...,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7702b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# The notion of data batches\n",
    "batch = train_images[:128]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae410659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "batch = train_images[128:256]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d1817f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db5ba17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3f629da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "052c6205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.00 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3dc8851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f77b2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting\n",
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed5c8b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(y, axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cdd389dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728],\n",
       "       [0.28066035, 0.45044534, 0.2454578 , 0.75364339, 0.29912727,\n",
       "        0.72111673, 0.80340035, 0.88226995, 0.69243532, 0.18584728]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "197f701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21a72676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.72762539, 0.77187697, 0.7269862 , ..., 0.3924717 ,\n",
       "          0.96327576, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.6400827 , ..., 0.75932309,\n",
       "          0.90321673, 0.9651287 ],\n",
       "         [0.25519939, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.12805884, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.1184059 , 0.89841293, ..., 0.90704984,\n",
       "          0.40531754, 0.79802856],\n",
       "         [0.61048397, 0.64903747, 0.50100135, ..., 0.89114464,\n",
       "          0.88641423, 0.69418562],\n",
       "         [0.87046015, 0.57263858, 0.31816552, ..., 0.37004554,\n",
       "          0.88466486, 0.27672315]],\n",
       "\n",
       "        [[0.78569122, 0.49322897, 0.90978405, ..., 0.04802598,\n",
       "          0.78611536, 0.97473311],\n",
       "         [0.97460953, 0.89205312, 0.09398752, ..., 0.75932309,\n",
       "          0.83602846, 0.9651287 ],\n",
       "         [0.96543976, 0.62877793, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.12805884, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.76257771, 0.89841293, ..., 0.90704984,\n",
       "          0.58594881, 0.59067649],\n",
       "         [0.81219661, 0.03449575, 0.8967428 , ..., 0.94249791,\n",
       "          0.71629105, 0.69418562],\n",
       "         [0.90804453, 0.33658103, 0.31816552, ..., 0.21042955,\n",
       "          0.4056458 , 0.27672315]],\n",
       "\n",
       "        [[0.94626977, 0.8265321 , 0.7269862 , ..., 0.0962283 ,\n",
       "          0.30829732, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.64684466, ..., 0.82228152,\n",
       "          0.45660168, 0.9651287 ],\n",
       "         [0.74775017, 0.97474126, 0.78635248, ..., 0.8629022 ,\n",
       "          0.91830821, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.14389909, 0.93667389, ..., 0.90704984,\n",
       "          0.73011673, 0.6554757 ],\n",
       "         [0.73514064, 0.38355968, 0.50100135, ..., 0.14997167,\n",
       "          0.4797292 , 0.95554187],\n",
       "         [0.445604  , 0.33658103, 0.59283379, ..., 0.39187642,\n",
       "          0.4056458 , 0.49750658]]],\n",
       "\n",
       "\n",
       "       [[[0.72762539, 0.69584109, 0.7269862 , ..., 0.46008247,\n",
       "          0.96129432, 0.99992215],\n",
       "         [0.85783918, 0.70802209, 0.89771228, ..., 0.75932309,\n",
       "          0.23386973, 0.9651287 ],\n",
       "         [0.76320107, 0.57823992, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.71607425, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.57904073, 0.89841293, ..., 0.90704984,\n",
       "          0.48892679, 0.76384308],\n",
       "         [0.61048397, 0.53572622, 0.50100135, ..., 0.29187205,\n",
       "          0.99299855, 0.69418562],\n",
       "         [0.5257071 , 0.75194199, 0.31816552, ..., 0.21042955,\n",
       "          0.45522272, 0.50568923]],\n",
       "\n",
       "        [[0.72762539, 0.43077983, 0.76278657, ..., 0.63790268,\n",
       "          0.89037533, 0.99834322],\n",
       "         [0.85783918, 0.70802209, 0.1681221 , ..., 0.75932309,\n",
       "          0.23386973, 0.9651287 ],\n",
       "         [0.47845359, 0.44406436, 0.98669441, ..., 0.8629022 ,\n",
       "          0.73643401, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.65663273, 0.89841293, ..., 0.90704984,\n",
       "          0.41061959, 0.25681147],\n",
       "         [0.85407587, 0.16300772, 0.69143524, ..., 0.03970373,\n",
       "          0.56044523, 0.69418562],\n",
       "         [0.86137094, 0.33658103, 0.61044762, ..., 0.21042955,\n",
       "          0.53680294, 0.82826805]],\n",
       "\n",
       "        [[0.93503118, 0.55414115, 0.7269862 , ..., 0.05530258,\n",
       "          0.53836468, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.86963575, ..., 0.75932309,\n",
       "          0.66332699, 0.9651287 ],\n",
       "         [0.25519939, 0.76865714, 0.9082967 , ..., 0.8629022 ,\n",
       "          0.39063155, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.46864898, 0.89841293, ..., 0.97046848,\n",
       "          0.40531754, 0.25681147],\n",
       "         [0.61048397, 0.1412472 , 0.50100135, ..., 0.72122128,\n",
       "          0.49418027, 0.69418562],\n",
       "         [0.42901053, 0.33658103, 0.81236221, ..., 0.70807048,\n",
       "          0.47135991, 0.98515742]]],\n",
       "\n",
       "\n",
       "       [[[0.72762539, 0.24929571, 0.7269862 , ..., 0.68101739,\n",
       "          0.94571754, 0.88152216],\n",
       "         [0.85783918, 0.94309007, 0.28949686, ..., 0.75932309,\n",
       "          0.23386973, 0.9651287 ],\n",
       "         [0.98698314, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.12805884, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.99703261, 0.89841293, ..., 0.90704984,\n",
       "          0.87427124, 0.6411868 ],\n",
       "         [0.7217074 , 0.54414642, 0.50100135, ..., 0.59816347,\n",
       "          0.67189737, 0.69418562],\n",
       "         [0.84095572, 0.33658103, 0.31816552, ..., 0.91771745,\n",
       "          0.41695188, 0.27672315]],\n",
       "\n",
       "        [[0.72762539, 0.55881795, 0.7269862 , ..., 0.03550364,\n",
       "          0.59877902, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.42320127, ..., 0.79675997,\n",
       "          0.49769485, 0.9651287 ],\n",
       "         [0.25519939, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.50766365, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.53435983, 0.89841293, ..., 0.90704984,\n",
       "          0.40531754, 0.58824272],\n",
       "         [0.77462936, 0.55120925, 0.50100135, ..., 0.65170205,\n",
       "          0.41996708, 0.69418562],\n",
       "         [0.42901053, 0.33658103, 0.6990935 , ..., 0.68255754,\n",
       "          0.69292305, 0.59515531]],\n",
       "\n",
       "        [[0.72762539, 0.79045587, 0.73232944, ..., 0.16686791,\n",
       "          0.30829732, 0.94861515],\n",
       "         [0.85783918, 0.70802209, 0.4632483 , ..., 0.75932309,\n",
       "          0.97498224, 0.9651287 ],\n",
       "         [0.91395385, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.92485921, 0.98217663],\n",
       "         ...,\n",
       "         [0.93017827, 0.30902721, 0.89841293, ..., 0.90704984,\n",
       "          0.47759898, 0.25681147],\n",
       "         [0.61048397, 0.89804326, 0.98872753, ..., 0.31071055,\n",
       "          0.65134538, 0.69418562],\n",
       "         [0.68654656, 0.94307063, 0.9443417 , ..., 0.95591861,\n",
       "          0.84761054, 0.91967929]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.72762539, 0.29489761, 0.7269862 , ..., 0.3863946 ,\n",
       "          0.74543289, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.75186749, ..., 0.75932309,\n",
       "          0.28063777, 0.9651287 ],\n",
       "         [0.25519939, 0.70734154, 0.7785619 , ..., 0.89238644,\n",
       "          0.97498866, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.97303063, 0.89841293, ..., 0.90704984,\n",
       "          0.47477103, 0.94936645],\n",
       "         [0.61048397, 0.2088343 , 0.50100135, ..., 0.5673565 ,\n",
       "          0.87253445, 0.97999805],\n",
       "         [0.62507376, 0.72489162, 0.6017583 , ..., 0.57658742,\n",
       "          0.99208191, 0.27672315]],\n",
       "\n",
       "        [[0.72762539, 0.24929571, 0.7269862 , ..., 0.48858868,\n",
       "          0.30829732, 0.90305378],\n",
       "         [0.85783918, 0.70802209, 0.57682233, ..., 0.75932309,\n",
       "          0.23386973, 0.9651287 ],\n",
       "         [0.25519939, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.43036001, 0.99246468],\n",
       "         ...,\n",
       "         [0.87846909, 0.1184059 , 0.89841293, ..., 0.90704984,\n",
       "          0.74519261, 0.63792436],\n",
       "         [0.61048397, 0.42578068, 0.88020744, ..., 0.04959302,\n",
       "          0.41996708, 0.83692645],\n",
       "         [0.42901053, 0.33658103, 0.63623638, ..., 0.63787433,\n",
       "          0.4056458 , 0.97577102]],\n",
       "\n",
       "        [[0.72762539, 0.72628072, 0.7269862 , ..., 0.90886876,\n",
       "          0.40815772, 0.91830126],\n",
       "         [0.85783918, 0.70802209, 0.73279096, ..., 0.75932309,\n",
       "          0.63856994, 0.9651287 ],\n",
       "         [0.49404793, 0.44406436, 0.86252922, ..., 0.8629022 ,\n",
       "          0.14612697, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.91594774, 0.89841293, ..., 0.90704984,\n",
       "          0.48053838, 0.25681147],\n",
       "         [0.61048397, 0.71063007, 0.92753269, ..., 0.26535385,\n",
       "          0.78200111, 0.69418562],\n",
       "         [0.57152738, 0.6893326 , 0.6677824 , ..., 0.60755716,\n",
       "          0.73867427, 0.75463775]]],\n",
       "\n",
       "\n",
       "       [[[0.72762539, 0.92746696, 0.7269862 , ..., 0.92257189,\n",
       "          0.36201419, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.85793394, ..., 0.75932309,\n",
       "          0.24123663, 0.9651287 ],\n",
       "         [0.46777485, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.67618363, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.60264006, 0.89841293, ..., 0.90704984,\n",
       "          0.40531754, 0.25681147],\n",
       "         [0.73554976, 0.4638523 , 0.66983026, ..., 0.42068194,\n",
       "          0.78949824, 0.69418562],\n",
       "         [0.93173339, 0.33658103, 0.69544603, ..., 0.29350301,\n",
       "          0.47069349, 0.73334405]],\n",
       "\n",
       "        [[0.82772114, 0.41750829, 0.92743526, ..., 0.07642647,\n",
       "          0.44416565, 0.88152216],\n",
       "         [0.85783918, 0.99673661, 0.54821179, ..., 0.76078832,\n",
       "          0.48150404, 0.9651287 ],\n",
       "         [0.54225809, 0.44406436, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.12805884, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.98048895, 0.89841293, ..., 0.90704984,\n",
       "          0.55600956, 0.52493208],\n",
       "         [0.61048397, 0.36572491, 0.50100135, ..., 0.84100913,\n",
       "          0.41996708, 0.69418562],\n",
       "         [0.66685186, 0.70027376, 0.31816552, ..., 0.9596462 ,\n",
       "          0.46888798, 0.37222241]],\n",
       "\n",
       "        [[0.72762539, 0.64574164, 0.7269862 , ..., 0.96289983,\n",
       "          0.42724214, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.81122965, ..., 0.75932309,\n",
       "          0.76588539, 0.9651287 ],\n",
       "         [0.25519939, 0.44406436, 0.78219254, ..., 0.98429076,\n",
       "          0.92862667, 0.98217663],\n",
       "         ...,\n",
       "         [0.90124257, 0.91238193, 0.89841293, ..., 0.90704984,\n",
       "          0.40531754, 0.25681147],\n",
       "         [0.61048397, 0.35923611, 0.72126531, ..., 0.51506177,\n",
       "          0.41996708, 0.69418562],\n",
       "         [0.42901053, 0.8719007 , 0.67608007, ..., 0.64515903,\n",
       "          0.97380663, 0.27672315]]],\n",
       "\n",
       "\n",
       "       [[[0.72762539, 0.24929571, 0.91542468, ..., 0.58946931,\n",
       "          0.47984257, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.3770921 , ..., 0.75932309,\n",
       "          0.23386973, 0.9651287 ],\n",
       "         [0.63014414, 0.44406436, 0.97560083, ..., 0.8629022 ,\n",
       "          0.19377244, 0.98217663],\n",
       "         ...,\n",
       "         [0.90609624, 0.69493948, 0.89841293, ..., 0.90704984,\n",
       "          0.674975  , 0.80377585],\n",
       "         [0.61048397, 0.15123286, 0.51922374, ..., 0.21603954,\n",
       "          0.49742649, 0.69418562],\n",
       "         [0.66193067, 0.33658103, 0.31816552, ..., 0.99456985,\n",
       "          0.47719905, 0.4967264 ]],\n",
       "\n",
       "        [[0.72762539, 0.9061698 , 0.7269862 , ..., 0.71639405,\n",
       "          0.73134964, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.41190539, ..., 0.75932309,\n",
       "          0.23386973, 0.9651287 ],\n",
       "         [0.82147313, 0.72244642, 0.7785619 , ..., 0.8629022 ,\n",
       "          0.87491815, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.31258099, 0.89841293, ..., 0.90704984,\n",
       "          0.90212141, 0.96462258],\n",
       "         [0.61048397, 0.47445619, 0.50100135, ..., 0.35677941,\n",
       "          0.82482159, 0.69418562],\n",
       "         [0.42901053, 0.34961676, 0.50461661, ..., 0.70920644,\n",
       "          0.65892442, 0.27672315]],\n",
       "\n",
       "        [[0.72762539, 0.24929571, 0.7269862 , ..., 0.99015513,\n",
       "          0.96719773, 0.88152216],\n",
       "         [0.85783918, 0.70802209, 0.68667491, ..., 0.75932309,\n",
       "          0.56776633, 0.9651287 ],\n",
       "         [0.32008541, 0.44406436, 0.98119977, ..., 0.8629022 ,\n",
       "          0.12805884, 0.98217663],\n",
       "         ...,\n",
       "         [0.87846909, 0.15973904, 0.89841293, ..., 0.90704984,\n",
       "          0.40531754, 0.91186141],\n",
       "         [0.76899593, 0.33512586, 0.60142896, ..., 0.32029233,\n",
       "          0.7511048 , 0.69418562],\n",
       "         [0.42901053, 0.33658103, 0.81781679, ..., 0.36415093,\n",
       "          0.72435927, 0.27672315]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1bc38806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0880981021239"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor product\n",
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d21a5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8bc0a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5cbe1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f2b1ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db55b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor reshaping\n",
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbfbf0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "958755c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24803589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e62b773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking back at our first example\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30932077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27ebf47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31a34ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2567 - accuracy: 0.9259\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.9684\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0697 - accuracy: 0.9791\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1421c26aaf0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6762b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimplementing our first example from scratch in TensorFlow\n",
    "# A simple Dense class\n",
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "441d79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple Sequential class\n",
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "               x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights\n",
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abe0deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A batch generator\n",
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ba8eebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running one training step\n",
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "337ce093",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00aecdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3925775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full training loop\n",
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00d0e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 5.30\n",
      "loss at batch 100: 2.22\n",
      "loss at batch 200: 2.19\n",
      "loss at batch 300: 2.08\n",
      "loss at batch 400: 2.19\n",
      "Epoch 1\n",
      "loss at batch 0: 1.86\n",
      "loss at batch 100: 1.85\n",
      "loss at batch 200: 1.80\n",
      "loss at batch 300: 1.69\n",
      "loss at batch 400: 1.79\n",
      "Epoch 2\n",
      "loss at batch 0: 1.54\n",
      "loss at batch 100: 1.55\n",
      "loss at batch 200: 1.48\n",
      "loss at batch 300: 1.41\n",
      "loss at batch 400: 1.47\n",
      "Epoch 3\n",
      "loss at batch 0: 1.29\n",
      "loss at batch 100: 1.32\n",
      "loss at batch 200: 1.22\n",
      "loss at batch 300: 1.20\n",
      "loss at batch 400: 1.25\n",
      "Epoch 4\n",
      "loss at batch 0: 1.10\n",
      "loss at batch 100: 1.14\n",
      "loss at batch 200: 1.03\n",
      "loss at batch 300: 1.04\n",
      "loss at batch 400: 1.09\n",
      "Epoch 5\n",
      "loss at batch 0: 0.96\n",
      "loss at batch 100: 1.01\n",
      "loss at batch 200: 0.89\n",
      "loss at batch 300: 0.93\n",
      "loss at batch 400: 0.97\n",
      "Epoch 6\n",
      "loss at batch 0: 0.86\n",
      "loss at batch 100: 0.90\n",
      "loss at batch 200: 0.79\n",
      "loss at batch 300: 0.84\n",
      "loss at batch 400: 0.89\n",
      "Epoch 7\n",
      "loss at batch 0: 0.78\n",
      "loss at batch 100: 0.82\n",
      "loss at batch 200: 0.72\n",
      "loss at batch 300: 0.77\n",
      "loss at batch 400: 0.83\n",
      "Epoch 8\n",
      "loss at batch 0: 0.72\n",
      "loss at batch 100: 0.75\n",
      "loss at batch 200: 0.66\n",
      "loss at batch 300: 0.71\n",
      "loss at batch 400: 0.78\n",
      "Epoch 9\n",
      "loss at batch 0: 0.67\n",
      "loss at batch 100: 0.70\n",
      "loss at batch 200: 0.61\n",
      "loss at batch 300: 0.67\n",
      "loss at batch 400: 0.74\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88336d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.81\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")\n",
    "\n",
    "# Summary\n",
    "print(train_images.itemsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
